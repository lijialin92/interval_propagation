{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b06456-02b1-413d-8768-166d8ba960a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use the functions in single_layer_interval_propagation\n",
    "%run single_layer_interval_propagation.ipynb\n",
    "%run simple_interval_propagation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadd0e2-03f2-406f-b43d-b6b202f97e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 5 x_train values: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "the first 5 y_train values: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test case 1 for simple_interval_propagation\n",
    "# keras mnist two layers NN model\n",
    "# first layer has 32 nodes and sigmoid as activation function;\n",
    "# second layer has 10 nodes(output classes) and sigmoid as activation function\n",
    "\n",
    "# **************************************get the trained model contains the layers(ws, bs) and activation_functions****************************************************\n",
    "# **************************************train the model************************************************************************\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# modification of y\n",
    "import keras\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"the first 5 x_train values: \" + str(x_train[:5]))\n",
    "print(\"the first 5 y_train values: \" + str(y_train[:5]))\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "\n",
    "# set the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=32, activation=\"sigmoid\", input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# plot the losses\n",
    "from matplotlib import pyplot as plt\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history=model.fit(x_train, y_train, batch_size=3000,epochs=2, verbose=0, validation_split=.1)\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "# save the model\n",
    "# model.save(\"mnist_two_layer_80%.h5\")\n",
    "# reconstructed_model = keras.models.load_model(\"mnist_two_layer.h5\")\n",
    "# reconstructed_model.summary()\n",
    "# ******************************************load the saved model*****************************************************************\n",
    "# model_1 = keras.models.load_model(\"mnist_two_layer.h5\")\n",
    "# # ******************************************get layers***********************************************************************\n",
    "# layers=[]\n",
    "# for layer in model_1.layers:\n",
    "#     layers.append(layer.get_weights())\n",
    "# # *****************************************get activation_functions*************************************************************** \n",
    "# # print(type(model.layers[0].activation))\n",
    "# # print(str(model.layers[0].activation))\n",
    "# activation_functions = [\"sigmoid\", \"sigmoid\"]\n",
    "# #*******************************************get input_min and input_max*******************************************************\n",
    "# min_vec = x_train[0]\n",
    "# max_vec = min_vec.copy()\n",
    "# for i in range(len(min_vec)):\n",
    "#     if max_vec[i] <= 250:\n",
    "#         max_vec[i] = min_vec[i] + 5\n",
    "#     else:\n",
    "#         max_vec[i] = 255\n",
    "# # ****************************************************************************************************************************\n",
    "# outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "# print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "# print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078e2478-b9ec-46da-a329-1ee7d3069ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output min vector is: \n",
      "[[0.4875026]\n",
      " [0.4875026]]\n",
      "the output max vector is: \n",
      "[[0.51231383]\n",
      " [0.54280407]]\n"
     ]
    }
   ],
   "source": [
    "# test case 2 for simple_interval_propagation\n",
    "min_vec = np.array([[0.], [-2.]])\n",
    "max_vec = np.array([[2.], [0.]])\n",
    "w1 = np.array([[0.3, -0.4], [-0.2, 0.6]])\n",
    "b1 = np.array([[0.],[0.]])\n",
    "w2 = np.array([[0.1, 0.3], [-0.2, -0.4]])\n",
    "b2 = np.array([[0.],[0.]])\n",
    "activation_function1 = \"sigmoid\"\n",
    "activation_function2 = \"sigmoid\"\n",
    "layer1 = [w1, b1]\n",
    "layer2 = [w2, b2]\n",
    "layers = [layer1, layer2]\n",
    "activation_functions = [activation_function1, activation_function2]\n",
    "#******************************************************************************************************************\n",
    "outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba8748bd-65b3-4cdb-896d-29bbad55da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output min vector is: \n",
      "[[0.]\n",
      " [0.]]\n",
      "the output max vector is: \n",
      "[[0.1]\n",
      " [0.3]]\n"
     ]
    }
   ],
   "source": [
    "# test case 2 for simple_interval_propagation\n",
    "min_vec = np.array([[0.], [-2.]])\n",
    "max_vec = np.array([[2.], [0.]])\n",
    "w1 = np.array([[0.3, -0.4], [-0.2, 0.6]])\n",
    "b1 = np.array([[0.],[0.]])\n",
    "w2 = np.array([[0.1, 0.3], [-0.2, -0.4]])\n",
    "b2 = np.array([[0.],[0.]])\n",
    "activation_function1 = \"relu\"\n",
    "activation_function2 = \"relu\"\n",
    "layer1 = [w1, b1]\n",
    "layer2 = [w2, b2]\n",
    "layers = [layer1, layer2]\n",
    "activation_functions = [activation_function1, activation_function2]\n",
    "#******************************************************************************************************************\n",
    "outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "905d3741-6064-4e0a-8b3d-790429ab0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output min vector is: \n",
      "[[-0.05]\n",
      " [-0.1 ]\n",
      " [-0.15]]\n",
      "the output max vector is: \n",
      "[[0.02]\n",
      " [0.05]\n",
      " [0.08]]\n"
     ]
    }
   ],
   "source": [
    "# test case 3 for simple_interval_propagation\n",
    "min_vec = np.array([[0.], [-2.]])\n",
    "max_vec = np.array([[2.], [0.]])\n",
    "w1 = np.array([[0.3, -0.4], [-0.2, 0.6]])\n",
    "b1 = np.array([[0.],[0.]])\n",
    "w2 = np.array([[0.1, 0.3], [-0.2, -0.4]])\n",
    "b2 = np.array([[0.],[0.]])\n",
    "w3 = np.array([[0.1, 0.3, 0.5], [-0.2, -0.4, -0.6]])\n",
    "b3 = np.array([[0.01],[0.02],[0.03]])\n",
    "activation_function1 = \"relu\"\n",
    "activation_function2 = \"relu\"\n",
    "activation_function3 = \"none\"\n",
    "layer1 = [w1, b1]\n",
    "layer2 = [w2, b2]\n",
    "layer3 = [w3, b3]\n",
    "layers = [layer1, layer2, layer3]\n",
    "activation_functions = [activation_function1, activation_function2, activation_function3]\n",
    "#******************************************************************************************************************\n",
    "outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "095fd6d3-448b-4a6a-b0b6-40ef201728fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 5 x_train values:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "the first 5 y_train values:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   8  23  23  23 131 141 180  31 171 255\n",
      " 252 132   0   0   0   0   0   0   0   0   0   0   0   0  35  41  99 159\n",
      " 175 255 255 255 255 255 230 177 255 247 200  69   0   0   0   0   0   0\n",
      "   0   0   0   0   0  54 243 255 255 255 255 255 255 255 255 255  98  87\n",
      "  87  61  44   0   0   0   0   0   0   0   0   0   0   0   0  23 224 255\n",
      " 255 255 255 255 203 187 252 246   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 161 112 255 255 210  16   0  48 159\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  19   6 159 255  95   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 144 255 195   7   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  16 195 255  75   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40 246\n",
      " 230 165 113   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  86 245 255 255 124  30   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  50 191 255 255 155  32   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  21  98 255 255 192\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 254 255 254  69   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 135 188 255\n",
      " 255 212   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  44 153 234 255 255 255 255 187   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  29 119 226 255 255 255\n",
      " 255 206  83   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  28  71 218 255 255 255 255 203  86   7   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  23 176 224 255 255 255 255 200\n",
      "  85  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  60 177 231 255 255 255 255 249 138  16   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 141 255 255 255 217 140 137  21\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "the output min vector is: \n",
      "[[0.48623414]\n",
      " [0.11544833]\n",
      " [0.53678026]\n",
      " [0.86376011]\n",
      " [0.11039225]\n",
      " [0.94890027]\n",
      " [0.17408449]\n",
      " [0.55943371]\n",
      " [0.65579484]\n",
      " [0.21776917]]\n",
      "the output max vector is: \n",
      "[[0.80495188]\n",
      " [0.24928442]\n",
      " [0.83986358]\n",
      " [0.93641337]\n",
      " [0.34355593]\n",
      " [0.97465937]\n",
      " [0.41902591]\n",
      " [0.79081513]\n",
      " [0.86557358]\n",
      " [0.42402444]]\n"
     ]
    }
   ],
   "source": [
    "# test case 4 for simple_interval_propagation\n",
    "# input minimum verctor is add 5 to non zero pixels.\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# modification of y\n",
    "import keras\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"the first 5 x_train values:\\n \" + str(x_train[:5]))\n",
    "print(\"the first 5 y_train values:\\n \" + str(y_train[:5]))\n",
    "\n",
    "# ******************************************load the saved model*****************************************************************\n",
    "model_1 = keras.models.load_model(\"mnist_two_layer.h5\")\n",
    "# ******************************************get layers***********************************************************************\n",
    "layers=[]\n",
    "for layer in model_1.layers:\n",
    "    layers.append(layer.get_weights())\n",
    "# *****************************************get activation_functions*************************************************************** \n",
    "# print(type(model.layers[0].activation))\n",
    "# print(str(model.layers[0].activation))\n",
    "activation_functions = [\"sigmoid\", \"sigmoid\"]\n",
    "#*******************************************get input_min and input_max*******************************************************\n",
    "min_vec = x_train[0]\n",
    "max_vec = min_vec.copy()\n",
    "for row in range(min_vec.shape[0]):\n",
    "    if min_vec[row] <= 250 and min_vec[row] != 0:\n",
    "        max_vec[row] = min_vec[row] + 5\n",
    "    elif min_vec[row] > 250:\n",
    "        max_vec[row] = 255\n",
    "# ****************************************************************************************************************************\n",
    "outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76543be7-8cf6-4fb6-bec6-f03170181735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 5 x_train values:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "the first 5 y_train values:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "the output min vector is: \n",
      "[[0.07126427]\n",
      " [0.04968111]\n",
      " [0.09156656]\n",
      " [0.26004844]\n",
      " [0.00984265]\n",
      " [0.625299  ]\n",
      " [0.06294502]\n",
      " [0.0771286 ]\n",
      " [0.10935523]\n",
      " [0.03884521]]\n",
      "the output max vector is: \n",
      "[[0.96439438]\n",
      " [0.80227413]\n",
      " [0.96312502]\n",
      " [0.9688933 ]\n",
      " [0.65990788]\n",
      " [0.98597165]\n",
      " [0.93162529]\n",
      " [0.92323979]\n",
      " [0.95224365]\n",
      " [0.71914605]]\n"
     ]
    }
   ],
   "source": [
    "# test case 5 for simple_interval_propagation\n",
    "# input minimum verctor is add 55 to non zero pixels.\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# modification of y\n",
    "import keras\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"the first 5 x_train values:\\n \" + str(x_train[:5]))\n",
    "print(\"the first 5 y_train values:\\n \" + str(y_train[:5]))\n",
    "\n",
    "# ******************************************load the saved model*****************************************************************\n",
    "model_1 = keras.models.load_model(\"mnist_two_layer.h5\")\n",
    "# ******************************************get layers***********************************************************************\n",
    "layers=[]\n",
    "for layer in model_1.layers:\n",
    "    layers.append(layer.get_weights())\n",
    "# *****************************************get activation_functions*************************************************************** \n",
    "# print(type(model.layers[0].activation))\n",
    "# print(str(model.layers[0].activation))\n",
    "activation_functions = [\"sigmoid\", \"sigmoid\"]\n",
    "#*******************************************get input_min and input_max*******************************************************\n",
    "min_vec = x_train[0]\n",
    "max_vec = min_vec.copy()\n",
    "for row in range(min_vec.shape[0]):\n",
    "    if min_vec[row] <= 200 and min_vec[row] != 0:\n",
    "        max_vec[row] = min_vec[row] + 55\n",
    "    elif min_vec[row] > 200:\n",
    "        max_vec[row] = 255\n",
    "# ****************************************************************************************************************************\n",
    "outputMin, outputMax = simple_interval_propagation(layers, activation_functions, min_vec, max_vec)\n",
    "print(\"the output min vector is: \\n\" + str(outputMin))\n",
    "print(\"the output max vector is: \\n\" + str(outputMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba4b4ff-7f61-436c-8421-75cb74b4e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70.]\n",
      " [ 7.]]\n",
      "[[80.]\n",
      " [20.]]\n",
      "[[80.]\n",
      " [ 7.]]\n",
      "[[90.]\n",
      " [20.]]\n"
     ]
    }
   ],
   "source": [
    "# test case 1 for split_2()\n",
    "min_vec = np.array([[70.], [7.]])\n",
    "max_vec = np.array([[90.], [20.]])\n",
    "region1=[]\n",
    "region2=[]\n",
    "\n",
    "region1, region2 = split_2(min_vec, max_vec)\n",
    "\n",
    "print(region1[0])\n",
    "print(region1[1])\n",
    "print(region2[0])\n",
    "print(region2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648b21a9-ff85-4000-ab03-51e6bde8345e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23963/1566351705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregion2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mregion1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23963/3718510105.py\u001b[0m in \u001b[0;36msplit_2\u001b[0;34m(min_vec, max_vec)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# check every elements in min_vec is smaller than max_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_vec\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mmax_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# the index of the largest gap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdif_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_vec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test case 2 for split_2()\n",
    "min_vec = np.array([[1.], [1.],[1.]])\n",
    "max_vec = np.array([[4.], [4.],[50.]])\n",
    "region1=[]\n",
    "region2=[]\n",
    "\n",
    "region1, region2 = split_2(min_vec, max_vec)\n",
    "\n",
    "print(region1[0])\n",
    "print(region1[1])\n",
    "print(region2[0])\n",
    "print(region2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d4b30-6cb1-4bcc-b3dd-bc30dbac78eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
